{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ex6_a.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0p0cmeMY5Wi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import collections\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axBPTS2okoo4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_words(message):\n",
        "    return [word.lower() for word in message.split()]\n",
        "\n",
        "\n",
        "def create_dictionary(messages):\n",
        "    temp = {}\n",
        "    mapping = {}\n",
        "    i = 0\n",
        "    for m in messages:\n",
        "        words = get_words(m)\n",
        "        for w in words:\n",
        "            if w not in temp:\n",
        "                temp[w] = 0\n",
        "            else:\n",
        "                temp[w] += 1\n",
        "            if temp[w] == 5:\n",
        "                mapping[w] = i\n",
        "                i += 1\n",
        "    return mapping\n",
        "\n",
        "\n",
        "def transform_text(messages, word_dictionary):\n",
        "    N, V = len(messages), len(word_dictionary)\n",
        "    data = np.zeros((N, V))\n",
        "    for i, m in enumerate(messages):\n",
        "        for w in get_words(m):\n",
        "            if w in word_dictionary:\n",
        "                data[i, word_dictionary[w]] += 1\n",
        "    return data"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vN93LGBGkwRU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Naive Bayes\n",
        "\n",
        "def fit_naive_bayes_model(matrix, labels):\n",
        "    # matrix (M, V)\n",
        "    labels = labels.astype(np.bool)\n",
        "    M, V = matrix.shape\n",
        "   \n",
        "    # frequency list, (2, |V|)\n",
        "    phi_k = np.zeros((2, V))\n",
        "    \n",
        "    # retrieve all ham messages\n",
        "    phi_k[0] = matrix[~labels].sum(axis=0)\n",
        "    phi_k[1] = matrix[labels].sum(axis=0)\n",
        "    \n",
        "    # add one laplace smoothing\n",
        "    phi_k += 1\n",
        "    \n",
        "    # normalize\n",
        "    phi_k = phi_k / phi_k.sum(axis=1, keepdims=True)\n",
        "    phi_y = labels.sum() / labels.shape[0]\n",
        "    \n",
        "    return phi_k, phi_y\n",
        "    \n",
        "\n",
        "def predict_from_naive_bayes_model(model, matrix):\n",
        "    # matrix (M, V)\n",
        "    # (2, V), scalar\n",
        "    phi_k, phi_y = model\n",
        "\n",
        "    # log likelihood (M, 2)\n",
        "    log_likelihood = np.sum(matrix[:,None] * np.log(phi_k), axis=-1)\n",
        "    log_likelihood[:, 0] += np.log(1 - phi_y)\n",
        "    log_likelihood[:, 1] += np.log(phi_y)\n",
        "    \n",
        "    return np.argmax(log_likelihood, axis=1)\n",
        "\n",
        "\n",
        "def get_top_five_naive_bayes_words(model, dictionary):\n",
        "    # (2, V)\n",
        "    phi_k, phi_y = model\n",
        "    ratio = phi_k[1] / phi_k[0]\n",
        "    indices = np.argsort(ratio)[-5:][::-1]  \n",
        "    idx2word = {v: k for k, v in dictionary.items()}\n",
        "    words = [idx2word[idx] for idx in indices]\n",
        "    return words"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnyysPAok12_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# SVM\n",
        "\n",
        "np.random.seed(42)\n",
        "def train_and_predict_svm(train_matrix, train_labels, test_matrix, radius):\n",
        "    model = svm_train(train_matrix, train_labels, radius)\n",
        "    return svm_predict(model, test_matrix, radius)\n",
        "\n",
        "def svm_train(matrix, category, radius):\n",
        "    state = {}\n",
        "    M, N = matrix.shape\n",
        "\n",
        "    Y = 2*category-1\n",
        "    matrix = 1.0*(matrix > 0)\n",
        "    squared = np.sum(matrix*matrix, axis=1)\n",
        "    gram = matrix.dot(matrix.T)\n",
        "    K = np.exp(-(squared.reshape((1, -1)) + squared.reshape((-1, 1)) - 2 * gram) / (2 * (radius ** 2)) )\n",
        "\n",
        "    alpha = np.zeros(M)\n",
        "    alpha_avg = np.zeros(M)\n",
        "    L = 1.0/(64*M)\n",
        "    outer_loops = 10\n",
        "\n",
        "    alpha_avg\n",
        "    for ii in range(outer_loops * M):\n",
        "        i = int(np.random.rand() * M)\n",
        "        margin = Y[i] * np.dot(K[i, :], alpha)\n",
        "        grad = M * L * K[:, i] * alpha[i]\n",
        "        if (margin < 1):\n",
        "            grad -=  Y[i] * K[:, i]\n",
        "        alpha -=  grad / np.sqrt(ii + 1)\n",
        "        alpha_avg += alpha\n",
        "\n",
        "    alpha_avg /= (ii + 1) * M\n",
        "\n",
        "    state[\"alpha\"] = alpha\n",
        "    state[\"alpha_avg\"] = alpha_avg\n",
        "    state[\"Xtrain\"] = matrix\n",
        "    state[\"Sqtrain\"] = squared\n",
        "\n",
        "    return state\n",
        "\n",
        "\n",
        "def svm_predict(state, matrix, radius):\n",
        "    M, N = matrix.shape\n",
        "    output = np.zeros(M)\n",
        "\n",
        "    Xtrain = state[\"Xtrain\"]\n",
        "    Sqtrain = state[\"Sqtrain\"]\n",
        "    matrix = 1. * (matrix > 0)\n",
        "    squared = np.sum(matrix * matrix, axis=1)\n",
        "    gram = matrix.dot(Xtrain.T)\n",
        "    K = np.exp(-(squared.reshape((-1, 1)) + Sqtrain.reshape((1, -1)) - 2 * gram) / (2 * (radius ** 2)))\n",
        "    alpha_avg = state[\"alpha_avg\"]\n",
        "    preds = K.dot(alpha_avg)\n",
        "    output = (1 + np.sign(preds)) // 2\n",
        "\n",
        "    return output\n",
        "\n",
        "\n",
        "def compute_best_svm_radius(train_matrix, train_labels, val_matrix, val_labels, radius_to_consider):\n",
        "    best_radius, best_acc = 0.0, 0.0\n",
        "\n",
        "    for r in radius_to_consider:\n",
        "        pred = train_and_predict_svm(train_matrix, train_labels, val_matrix, r)\n",
        "        acc = (pred == val_labels).sum() / len(pred)\n",
        "        if acc > best_acc:\n",
        "            best_radius = r\n",
        "            best_acc = acc\n",
        "    return best_radius"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPgZ2JgylugC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "ef7d8e4d-e131-4941-b357-232a6883c799"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "#train dataset\n",
        "train = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/CS229/ps2/data/ds6_train.tsv\", delimiter=\"\\t\", header=None, names=[\"labels\", \"messages\"])\n",
        "train_messages = []\n",
        "train_labels = []\n",
        "for l, m in zip(train[\"labels\"], train[\"messages\"]):\n",
        "    train_messages.append(m)\n",
        "    train_labels.append(1 if l == 'spam' else 0)\n",
        "train_labels = np.array(train_labels)\n",
        "\n",
        "#val dataset\n",
        "val = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/CS229/ps2/data/ds6_val.tsv\", sep=\"\\t\", header=None, names=[\"labels\", \"messages\"])\n",
        "val_messages = []\n",
        "val_labels = []\n",
        "for l, m in zip(val[\"labels\"], val[\"messages\"]):\n",
        "    val_messages.append(m)\n",
        "    val_labels.append(1 if l == 'spam' else 0)\n",
        "val_labels = np.array(val_labels)\n",
        "\n",
        "#test dataset\n",
        "test = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/CS229/ps2/data/ds6_test.tsv\", sep=\"\\t\", header=None, names=[\"labels\", \"messages\"])\n",
        "test_messages = []\n",
        "test_labels = []\n",
        "for l, m in zip(test[\"labels\"], test[\"messages\"]):\n",
        "    test_messages.append(m)\n",
        "    test_labels.append(1 if l == 'spam' else 0)\n",
        "test_labels = np.array(test_labels)\n",
        "\n",
        "#dictionary\n",
        "dictionary = create_dictionary(train_messages)\n",
        "\n",
        "#write json\n",
        "#import json\n",
        "#with open(\"/content/drive/My Drive/Colab Notebooks/CS229/ps2/output/p06_dictionary\", \"w\") as f:\n",
        "#    json.dump(dictionary, f)\n",
        "\n",
        "#matrix\n",
        "train_matrix = transform_text(train_messages, dictionary)\n",
        "#np.savetxt(\"/content/drive/My Drive/Colab Notebooks/CS229/ps2/output/p06_sample_train_matrix\", train_matrix[:100,:])\n",
        "\n",
        "#val\n",
        "val_matrix = transform_text(val_messages, dictionary)\n",
        "test_matrix = transform_text(test_messages, dictionary)\n",
        "\n",
        "#naive bayes\n",
        "naive_bayes_model = fit_naive_bayes_model(train_matrix, train_labels)\n",
        "naive_bayes_predictions = predict_from_naive_bayes_model(naive_bayes_model, test_matrix)\n",
        "#np.savetxt(\"/content/drive/My Drive/Colab Notebooks/CS229/ps2/output/p06_naive_bayes_predictions\", naive_bayes_predictions)\n",
        "naive_bayes_accuracy = np.mean(naive_bayes_predictions == test_labels)\n",
        "print(\"Naive Bayes had an accuracy of {} on the testing set\".format(naive_bayes_accuracy))\n",
        "\n",
        "#top 5\n",
        "top_5_words = get_top_five_naive_bayes_words(naive_bayes_model, dictionary)\n",
        "print(\"\\nThe top 5 indicative words for Naive Bayes are: \", top_5_words)\n",
        "\n",
        "#svm\n",
        "optimal_radius = compute_best_svm_radius(train_matrix, train_labels, val_matrix, val_labels, [0.01, 0.1, 1, 10])\n",
        "print(\"\\nThe optimal SVM radius was {}\".format(optimal_radius))\n",
        "\n",
        "svm_predictions = train_and_predict_svm(train_matrix, train_labels, test_matrix, optimal_radius)\n",
        "svm_accuracy = np.mean(svm_predictions == test_labels)\n",
        "\n",
        "print(\"\\nThe SVM model had an accuracy of {} on the testing set\".format(svm_accuracy, optimal_radius))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Naive Bayes had an accuracy of 0.978494623655914 on the testing set\n",
            "\n",
            "The top 5 indicative words for Naive Bayes are:  ['claim', 'won', 'prize', 'tone', 'urgent!']\n",
            "\n",
            "The optimal SVM radius was 0.1\n",
            "\n",
            "The SVM model had an accuracy of 0.967741935483871 on the testing set\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
