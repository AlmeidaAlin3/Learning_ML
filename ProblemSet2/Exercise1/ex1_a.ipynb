{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Training model on data set A ====\n",
      "Finished 10000 iterations\n",
      "Finished 20000 iterations\n",
      "Finished 30000 iterations\n",
      "Finished 40000 iterations\n",
      "Finished 50000 iterations\n",
      "Finished 60000 iterations\n",
      "Finished 70000 iterations\n",
      "Finished 80000 iterations\n",
      "Finished 90000 iterations\n",
      "Finished 100000 iterations\n",
      "Finished 110000 iterations\n",
      "Finished 120000 iterations\n",
      "Finished 130000 iterations\n",
      "Finished 140000 iterations\n",
      "Finished 150000 iterations\n",
      "Finished 160000 iterations\n",
      "Finished 170000 iterations\n",
      "Finished 180000 iterations\n",
      "Finished 190000 iterations\n",
      "Finished 200000 iterations\n",
      "Finished 210000 iterations\n",
      "Finished 220000 iterations\n",
      "Finished 230000 iterations\n",
      "Finished 240000 iterations\n",
      "Finished 250000 iterations\n",
      "Finished 260000 iterations\n",
      "Finished 270000 iterations\n",
      "Converged in 278103 iterations\n",
      "\n",
      "==== Training model on data set B ====\n",
      "Finished 10000 iterations\n",
      "Finished 20000 iterations\n",
      "Finished 30000 iterations\n",
      "Finished 40000 iterations\n",
      "Finished 50000 iterations\n",
      "Finished 60000 iterations\n",
      "Finished 70000 iterations\n",
      "Finished 80000 iterations\n",
      "Finished 90000 iterations\n",
      "Finished 100000 iterations\n",
      "Finished 110000 iterations\n",
      "Finished 120000 iterations\n",
      "Finished 130000 iterations\n",
      "Finished 140000 iterations\n",
      "Finished 150000 iterations\n",
      "Finished 160000 iterations\n",
      "Finished 170000 iterations\n",
      "Finished 180000 iterations\n",
      "Finished 190000 iterations\n",
      "Finished 200000 iterations\n",
      "Finished 210000 iterations\n",
      "Finished 220000 iterations\n",
      "Finished 230000 iterations\n",
      "Finished 240000 iterations\n",
      "Finished 250000 iterations\n",
      "Finished 260000 iterations\n",
      "Finished 270000 iterations\n",
      "Finished 280000 iterations\n",
      "Finished 290000 iterations\n",
      "Finished 300000 iterations\n",
      "Finished 310000 iterations\n",
      "Finished 320000 iterations\n",
      "Finished 330000 iterations\n",
      "Finished 340000 iterations\n",
      "Finished 350000 iterations\n",
      "Finished 360000 iterations\n",
      "Finished 370000 iterations\n",
      "Finished 380000 iterations\n",
      "Finished 390000 iterations\n",
      "Finished 400000 iterations\n",
      "Finished 410000 iterations\n",
      "Finished 420000 iterations\n",
      "Finished 430000 iterations\n",
      "Finished 440000 iterations\n",
      "Finished 450000 iterations\n",
      "Finished 460000 iterations\n",
      "Finished 470000 iterations\n",
      "Finished 480000 iterations\n",
      "Finished 490000 iterations\n",
      "Finished 500000 iterations\n",
      "Finished 510000 iterations\n",
      "Finished 520000 iterations\n",
      "Finished 530000 iterations\n",
      "Finished 540000 iterations\n",
      "Finished 550000 iterations\n",
      "Finished 560000 iterations\n",
      "Finished 570000 iterations\n",
      "Finished 580000 iterations\n",
      "Finished 590000 iterations\n",
      "Finished 600000 iterations\n",
      "Finished 610000 iterations\n",
      "Finished 620000 iterations\n",
      "Finished 630000 iterations\n",
      "Finished 640000 iterations\n",
      "Finished 650000 iterations\n",
      "Finished 660000 iterations\n",
      "Finished 670000 iterations\n",
      "Finished 680000 iterations\n",
      "Finished 690000 iterations\n",
      "Finished 700000 iterations\n",
      "Finished 710000 iterations\n",
      "Finished 720000 iterations\n",
      "Finished 730000 iterations\n",
      "Finished 740000 iterations\n",
      "Finished 750000 iterations\n",
      "Finished 760000 iterations\n",
      "Finished 770000 iterations\n",
      "Finished 780000 iterations\n",
      "Finished 790000 iterations\n",
      "Finished 800000 iterations\n",
      "Finished 810000 iterations\n",
      "Finished 820000 iterations\n",
      "Finished 830000 iterations\n",
      "Finished 840000 iterations\n",
      "Finished 850000 iterations\n",
      "Finished 860000 iterations\n",
      "Finished 870000 iterations\n",
      "Finished 880000 iterations\n",
      "Finished 890000 iterations\n",
      "Finished 900000 iterations\n",
      "Finished 910000 iterations\n",
      "Finished 920000 iterations\n",
      "Finished 930000 iterations\n",
      "Finished 940000 iterations\n",
      "Finished 950000 iterations\n",
      "Finished 960000 iterations\n",
      "Finished 970000 iterations\n",
      "Finished 980000 iterations\n",
      "Finished 990000 iterations\n",
      "Finished 1000000 iterations\n",
      "Finished 1010000 iterations\n",
      "Finished 1020000 iterations\n",
      "Finished 1030000 iterations\n",
      "Finished 1040000 iterations\n",
      "Finished 1050000 iterations\n",
      "Finished 1060000 iterations\n",
      "Finished 1070000 iterations\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-690c45a2962b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-690c45a2962b>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n==== Training model on data set B ===='\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0mXb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/ds1_b.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_intercept\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0mlogistic_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-690c45a2962b>\u001b[0m in \u001b[0;36mlogistic_regression\u001b[0;34m(X, Y)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mprev_theta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mtheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheta\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10000\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-690c45a2962b>\u001b[0m in \u001b[0;36mcalc_grad\u001b[0;34m(X, Y, theta)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mmargins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmargins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Important note: you do not have to modify this file for your homework.\n",
    "\n",
    "import util\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def calc_grad(X, Y, theta):\n",
    "    \"\"\"Compute the gradient of the loss with respect to theta.\"\"\"\n",
    "    m, n = X.shape\n",
    "\n",
    "    margins = Y * X.dot(theta)\n",
    "    probs = 1. / (1 + np.exp(margins))\n",
    "    grad = -(1./m) * (X.T.dot(probs * Y))\n",
    "\n",
    "    return grad\n",
    "\n",
    "\n",
    "def logistic_regression(X, Y):\n",
    "    \"\"\"Train a logistic regression model\"\"\"\n",
    "    m, n = X.shape\n",
    "    theta = np.zeros(n)\n",
    "    learning_rate = 1\n",
    "\n",
    "    i = 0\n",
    "    while True:\n",
    "        i += 1\n",
    "        prev_theta = theta\n",
    "        grad = calc_grad(X, Y, theta)\n",
    "        theta = theta - learning_rate * grad\n",
    "        if i % 10000 == 0:\n",
    "            DEBUG = False\n",
    "            if DEBUG:\n",
    "                from util import plot\n",
    "                from matplotlib import pyplot as plt\n",
    "                plot(X, (Y == 1), theta, 'output/{}.png'.format(i))\n",
    "            print('Finished %d iterations' % i)\n",
    "            # print(np.linalg.norm(prev_theta - theta))\n",
    "        if np.linalg.norm(prev_theta - theta) < 1e-15:\n",
    "            print('Converged in %d iterations' % i)\n",
    "            break\n",
    "    return\n",
    "\n",
    "\n",
    "def main():\n",
    "    # plot\n",
    "    DEBUG = False\n",
    "    if DEBUG:\n",
    "        from util import plot_points\n",
    "        from matplotlib import pyplot as plt\n",
    "        plt.figure()\n",
    "        Xa, Ya = util.load_csv('../data/ds1_a.csv', add_intercept=False)\n",
    "        Ya = (Ya == 1).astype(np.float)\n",
    "        plot_points(Xa, Ya)\n",
    "\n",
    "        plt.figure()\n",
    "        Xb, Yb = util.load_csv('../data/ds1_b.csv', add_intercept=False)\n",
    "        Yb = (Yb == 1).astype(np.float)\n",
    "        plot_points(Xb, Yb)\n",
    "        plt.show()\n",
    "        import sys\n",
    "        sys.exit()\n",
    "    \n",
    "    print('==== Training model on data set A ====')\n",
    "    Xa, Ya = util.load_csv('../data/ds1_a.csv', add_intercept=True)\n",
    "    logistic_regression(Xa, Ya)\n",
    "\n",
    "    print('\\n==== Training model on data set B ====')\n",
    "    Xb, Yb = util.load_csv('../data/ds1_b.csv', add_intercept=True)\n",
    "    logistic_regression(Xb, Yb)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
